{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll introduce some of the basic concepts of the Pandas library for data manipulation. We'll also see simple chart examples using both Pandas and Seaborn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas holds data in memory. As a general rule of thumb, you should have 5-10 times as much RAM as the size of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be aware that some operations in Pandas are computationally expensive - we won't cover the details here, but you can sometimes speed up your code by orders of magnitude just by doing things in a slightly different way..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of things are changing in pandas... Version 1.0 is due for release in mid-2019, and will see some big changes. See [this article](https://www.dataschool.io/future-of-pandas/) for an overview. In particular, `inplace` is being deprecated, and the back end will eventually change to Apache Arrow, to improve performance, and because:\n",
    "\n",
    "    \"The more you know about the internals of pandas DataFrame,\n",
    "    the more horrified you are.\"\n",
    "\n",
    "    Wes McKinney @ SciPy 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pandas data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important Pandas objects are the `Series` and the `DataFrame`\n",
    "s = pd.Series({'x': 10, 'y': 20, 'z': 30})\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can slice a series in a similar way to a Python list\n",
    "s[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also select using the index\n",
    "s['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['x', 'z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When slicing a series, pandas returns a copy, similar to what we saw with python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.random.randn(100))\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = s[:10]\n",
    "s2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2[:] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this behaviour becomes more complex when we use other slicing / indexing methods, or for DataFrames. If in doubt, do it explicitly instead of relying on implicit behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is like a SAS dataset or a R dataframe (or tibble). Each column of a DataFrame is a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'x': np.random.randn(100), \n",
    "                   'y': np.random.randint(0, 100, 100),\n",
    "                   'z': np.random.choice(list('abcde'), 100)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only going to scratch the surface of selecting from Series and DataFrames. For more info, see the Pandas documentation or (better) the [Python Data Science Handbook, chapter 3](https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set an index on the DataFrame:\n",
    "df.set_index('z', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can select all records where the index = 'c':\n",
    "df.loc['c'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc looks at the \"explicit\" index - i.e. the one we've defined. In contrast, .iloc looks at the \"implicit\" \n",
    "# index, which is just the row number. So to select rows 5 to 9:\n",
    "df.iloc[5:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see some examples on the web that use the .ix method for indexing. Don't do this - it's deprecated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often unclear whether pandas will return a view or a copy of a series or dataframe. If in doubt, do it explicitly! For example, lets say we want to assign a new value to the 'x' column, for all rows where the index = 'c'. We might think we could do this by taking a slice and then assigning to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice = df.loc['c']\n",
    "df_slice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could try to do this by assigning to the slice:\n",
    "df_slice.loc['x'] = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see that warning message, you should probably look for another way of doing things. In this case, our slice was actually a copy, so pandas is warning us that we might not be doing what we think we're doing. Here's a better way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['c', 'x'] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['c'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see some more indexing examples below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our dataset - the Tableau superstore data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    superstore = pd.read_excel('data/superstore.xslx')\n",
    "except FileNotFoundError:\n",
    "    superstore = pd.read_excel('https://query.data.world/s/n2pyux2nabxy4c43zl3uugxsk5gt6v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: do we have the right number of rows?\n",
    "assert len(superstore) == 51290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(superstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few basic data exploration tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic summary of the table\n",
    "superstore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many countries do we have?\n",
    "superstore['Country'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of countries\n",
    "superstore['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total sales\n",
    "superstore['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values for each column\n",
    "superstore.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick look at the distributions of numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdata = superstore.select_dtypes('number').drop('Postal Code', axis=1)\n",
    "plotdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(plotdata.melt(), col='variable', col_wrap=3, sharey=False, sharex=False)\n",
    "g.map(sns.distplot, 'value', kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregations: [Split, apply, combine](https://jakevdp.github.io/PythonDataScienceHandbook/03.08-aggregation-and-grouping.html#GroupBy:-Split,-Apply,-Combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by segment\n",
    "# select sum(Sales) from superstore group by Segment\n",
    "superstore.groupby('Segment')['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by market and segment\n",
    "# select sum(Sales) from superstore group by Market, Segment\n",
    "superstore.groupby(['Market', 'Segment'])['Sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can store the results of a query in an object:\n",
    "sales_summary = superstore.groupby(['Market', 'Segment'])['Sales'].sum()\n",
    "type(sales_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now have an example of a 'multi-index' (or hierarchical index)\n",
    "sales_summary.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were the sales figures for Asia Pacific?\n",
    "sales_summary['Asia Pacific']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What were the sales for Consumer and Corporate segments in Europe?\n",
    "sales_summary.loc[('Europe', ['Consumer', 'Corporate'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic plotting: Sales by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superstore.set_index('Order Date').resample('1M')['Sales'].sum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bar chart: Sales by market\n",
    "\n",
    "This demonstrates how getting a chart to look just the way you want it can get very fiddly very quickly! That's where recent plotting libraries such as Seaborn, Plotly, Chartify etc can be better than the built-in Pandas plotting methods, or doing it from scratch in matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, choose our bar colour. By default, pandas uses a different colour for each bar - nasty!\n",
    "colours = sns.color_palette('tab20') \n",
    "bar_colour = colours[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    ax = superstore.groupby('Market')['Sales'].sum().sort_values().plot.barh(color=bar_colour)\n",
    "\n",
    "    plt.title(\"Total sales by market (Â£000)\")\n",
    "    ax.yaxis.label.set_visible(False)\n",
    "    \n",
    "    # Now format the axis labels. It really shouldn't be this hard...\n",
    "    vals = ax.get_xticks()\n",
    "    ax.set_xticklabels(['{:,.0f}'.format(x/1000) for x in vals]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations: creating new columns etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ... and create profit ratio column (profit / sales)\n",
    "grouped = superstore.groupby('Segment')[['Sales', 'Profit']].sum()\n",
    "grouped['profit_ratio'] = grouped['Profit'] / grouped['Sales']\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merges etc. Contrast SQL - which has to run on a database - with Pandas, which runs in memory. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
